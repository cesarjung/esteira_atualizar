import time, random, re, unicodedata
from datetime import datetime

import os, json, pathlib
import gspread
import pandas as pd
from google.oauth2.service_account import Credentials
from gspread.exceptions import APIError
from gspread.utils import rowcol_to_a1, a1_to_rowcol

# ---------- CONFIG ----------
ORIGEM_ID     = '1lUNIeWCddfmvJEjWJpQMtuR4oRuMsI3VImDY0xBp3Bs'
DESTINO_ID    = '1gDktQhF0WIjfAX76J2yxQqEeeBsSfMUPGs5svbf9xGM'
ABA_ORIGEM    = 'Carteira'
ABA_DESTINO   = 'Carteira'
CRED_JSON     = 'credenciais.json'   # fallback local

# Colunas da ORIGEM na ordem desejada
COLS_ORIGEM   = ['A','Z','B','C','D','E','U','T','N','AA','AB','CN','CQ','CR','CS','BQ','CE','V']
# Colunas de data (da ORIGEM) que viram L..Q no DESTINO
DATE_LETTERS  = ['CN','CQ','CR','CS','BQ','CE']  # 6 datas â†’ L..Q

CHUNK_ROWS    = 2000
MAX_RETRIES   = 6
FORCAR_DESTAQ = False  # destaque amarelo nas inserÃ§Ãµes

# Mapeamento de Unidades (usado em CICLO.Dâ†’R e LV.Aâ†’R)
MAP_UNIDADE = {
    'CONQUISTA': 'VITORIA DA CONQUISTA',
    'ITAPETINGA': 'ITAPETINGA',
    'JEQUIE': 'JEQUIE',
    'GUANAMBI': 'GUANAMBI',
    'BARREIRAS': 'BARREIRAS',
    'LAPA': 'BOM JESUS DA LAPA',
    'IRECE': 'IRECE',
    'IBOTIRAMA': 'IBOTIRAMA',
    'BRUMADO': 'BRUMADO',
    'LIVRAMENTO': 'LIVRAMENTO',
}

# ---------- LOG & RETRY ----------
def now(): return datetime.now().strftime('%d/%m/%Y %H:%M:%S')
def log(msg): print(f"[{now()}] {msg}", flush=True)

RETRYABLE_CODES = {429, 500, 502, 503, 504}

def _status_code_from_apierror(e: APIError):
    m = re.search(r"\[(\d+)\]", str(e))
    return int(m.group(1)) if m else None

def _sleep_backoff(attempt, base=1.0):
    # backoff exponencial + jitter, com teto
    time.sleep(min(60.0, base * (2 ** (attempt - 1)) + random.uniform(0, 0.8)))

def with_retry(fn, *a, desc="", base=1, maxr=MAX_RETRIES, **k):
    r = 0
    while True:
        try:
            return fn(*a, **k)
        except APIError as e:
            r += 1
            code = _status_code_from_apierror(e)
            if r >= maxr or (code is not None and code not in RETRYABLE_CODES):
                log(f"âŒ {desc or fn.__name__}: {e}")
                raise
            # 429: espere um pouco mais
            if code == 429:
                wait = min(60.0, 5.0 * r + random.uniform(0, 2.0))
                log(f"âš ï¸  {e} â€” retry {r}/{maxr-1} em {wait:.1f}s ({desc or fn.__name__})")
                time.sleep(wait)
            else:
                s = min(60, base * 2 ** (r - 1) + random.uniform(0, .75))
                log(f"âš ï¸  {e} â€” retry {r}/{maxr-1} em {s:.1f}s ({desc or fn.__name__})")
                time.sleep(s)

# ---------- HELPERS ----------
def col_letter(n): return re.sub(r'\d','',rowcol_to_a1(1,n))
def a1index(L):    return a1_to_rowcol(f"{L}1")[1]

def ensure(ws, r, c):
    if ws.row_count < r or ws.col_count < c:
        log(f"ğŸ§© resize â†’ {r}x{c}")
        with_retry(ws.resize, r, c, desc="resize")

def norm_acento_up(s: str) -> str:
    if s is None: return ''
    s = str(s).strip().upper()
    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')

def normalize(v):
    if v is None: return ""
    try:
        if pd.isna(v): return ""
    except: pass
    if isinstance(v,(pd.Timestamp,datetime)): return v.strftime("%d/%m/%Y")
    return v

def df2values(df): return [[normalize(c) for c in row] for row in df.values.tolist()]

def parse_dates(sr):
    s = pd.to_datetime(sr, dayfirst=True, errors='coerce')
    m = s.isna()
    if m.any():
        n = pd.to_numeric(sr, errors='coerce')
        s = s.where(~m, pd.to_datetime(n, unit='D', origin='1899-12-30', errors='coerce'))
    return s.dt.strftime('%d/%m/%Y').where(s.notna(), "")

# ---------- Leituras RESILIENTES e DELIMITADAS ----------
def get_with_retry(ws, a1_range: str, max_tries=MAX_RETRIES, base_sleep=1.1):
    for attempt in range(1, max_tries + 1):
        try:
            return ws.get(a1_range)
        except APIError as e:
            code = _status_code_from_apierror(e)
            if code not in RETRYABLE_CODES or attempt >= max_tries:
                raise
            if code == 429:
                wait = min(60.0, 5.0 * attempt + random.uniform(0, 2.0))
                log(f"[get_with_retry] 429 em {a1_range} â€” aguardando {wait:.1f}sâ€¦")
                time.sleep(wait)
            else:
                log(f"[get_with_retry] {code} em {a1_range} â€” retry {attempt}/{max_tries-1}")
                _sleep_backoff(attempt, base_sleep)
    return []

def load_col_bounded(ws, L, chunk_rows=10000):
    """
    LÃª uma coluna L a partir da linha 2 atÃ© row_count, com fallback em chunks
    se a leitura inteira falhar.
    """
    end_row = max(ws.row_count or 0, 2)
    if end_row < 2:
        return []
    a1 = f"{L}2:{L}{end_row}"
    try:
        raw = get_with_retry(ws, a1)
        return [(r[0].strip() if r and r[0] else "") for r in raw]
    except APIError as e:
        log(f"[load_col_bounded] downgrade para chunks ({L}) por erro: {e}")
        # fallback: ler em pedaÃ§os
        out = []
        start = 2
        while start <= end_row:
            stop = min(end_row, start + chunk_rows - 1)
            part = get_with_retry(ws, f"{L}{start}:{L}{stop}")
            out.extend([(r[0].strip() if r and r[0] else "") for r in part])
            start = stop + 1
        return out

def load_col(ws, L):
    """
    MantÃ©m a assinatura usada no seu cÃ³digo,
    agora usando a versÃ£o delimitada e resiliente.
    """
    return load_col_bounded(ws, L)

def highlight(ws, start, count, end_col="Q"):
    if not FORCAR_DESTAQ or count <= 0: return
    try:
        from gspread_formatting import format_cell_range,CellFormat,Color
        rng=f"A{start}:{end_col}{start+count-1}"
        yellow=CellFormat(backgroundColor=Color(1,1,0.6))
        with_retry(format_cell_range, ws, rng, yellow, desc=f"highlight {rng}")
        log("ğŸ¨ InserÃ§Ãµes destacadas em amarelo.")
    except Exception as e:
        log(f"âš ï¸  Falhou ao colorir: {e}")

# ---------- AUTH (Secret ou arquivo local) ----------
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def make_creds():
    env = os.environ.get("GOOGLE_CREDENTIALS")
    if env:
        return Credentials.from_service_account_info(json.loads(env), scopes=SCOPES)
    return Credentials.from_service_account_file(pathlib.Path(CRED_JSON), scopes=SCOPES)

log("ğŸ” Autenticandoâ€¦")
gc = gspread.authorize(make_creds())

log("ğŸ“‚ Abrindo planilhasâ€¦")
b_src = with_retry(gc.open_by_key, ORIGEM_ID,  desc="open origem")
b_dst = with_retry(gc.open_by_key, DESTINO_ID, desc="open destino")
w_src = with_retry(b_src.worksheet, ABA_ORIGEM,  desc="ws origem")
w_dst = with_retry(b_dst.worksheet, ABA_DESTINO, desc="ws destino")

ensure(w_dst, 2, 20)  # por causa do status em T2

# ---------- LEITURA ORIGEM ----------
lastL = col_letter(max(a1index(c) for c in COLS_ORIGEM))
rng   = f"A5:{lastL}"
log(f"ğŸ§­ Lendo cabeÃ§alho (linha 5) e dadosâ€¦ ({rng})")
dat   = with_retry(w_src.get, rng, desc=f"get {rng}")
hdr, rows = dat[0], dat[1:]

idx      = [a1index(c)-1 for c in COLS_ORIGEM]
tbl      = [[r[i] if i<len(r) else "" for i in idx] for r in rows if r and r[0].strip()]
df       = pd.DataFrame(tbl, columns=[hdr[i] if i<len(hdr) else "" for i in idx])
log(f"ğŸ§± Origem: {len(df)} linhas Ã— {len(df.columns)} colunas")

# datas L..Q
pos = {l:i for i,l in enumerate(COLS_ORIGEM)}
for l in DATE_LETTERS:
    p = pos[l]
    if p < len(df.columns):
        df.iloc[:,p] = parse_dates(df.iloc[:,p])

# num AC (se existir)
if "AC" in df.columns:
    df["AC"] = pd.to_numeric(df["AC"].astype(str)
                             .str.replace("R$","",regex=False)
                             .str.replace(".","",regex=False)
                             .str.replace(",",".",regex=False),
                             errors='coerce')

# ---------- ESCRITA PRINCIPAL ----------
vals  = df2values(df)
rows0 = len(vals)
cols0 = len(df.columns)

ensure(w_dst, rows0+1, max(20, cols0))
endL  = col_letter(max(1, cols0))
with_retry(w_dst.batch_clear, [f"A2:{endL}"], desc="clear dados")
with_retry(w_dst.update,
           range_name=f"A1:{rowcol_to_a1(1,cols0)}",
           values=[list(df.columns)],
           value_input_option='USER_ENTERED')
with_retry(w_dst.update, range_name="T2",
           values=[[f"Atualizando... {now()}"]],
           value_input_option='USER_ENTERED')

if vals:
    log(f"ğŸšš Escrevendo {rows0} linhas em blocos de {CHUNK_ROWS}â€¦")
    i=0
    while i<rows0:
        part=vals[i:i+CHUNK_ROWS]
        a1=f"A{2+i}:{endL}{1+i+len(part)}"
        with_retry(w_dst.update, range_name=a1, values=part, value_input_option='USER_ENTERED')
        i+=len(part)
log("âœ… Escrita de Carteira concluÃ­da.")

# ---------- CICLO (Eâ†’A Fâ†’B Câ†’H Lâ†’K Dâ†’R) ----------
log("ğŸ”— CICLO (Eâ†’A, Fâ†’B, Câ†’H, Lâ†’K, Dâ†’R)")
w_ciclo = with_retry(b_dst.worksheet, "CICLO", desc="ws CICLO")

# Leituras resilientes e DELIMITADAS
E  = load_col(w_ciclo, "E")   # â†’ A (ID/chave)
F  = load_col(w_ciclo, "F")   # â†’ B
C  = load_col(w_ciclo, "C")   # â†’ H
L_ = load_col(w_ciclo, "L")   # â†’ K
D  = load_col(w_ciclo, "D")   # â†’ R (unidade mapeada)

# IDs jÃ¡ existentes (delimitado atÃ© o fim atual da planilha de destino)
exist_A = load_col_bounded(w_dst, "A")
exist = set(v for v in exist_A if v)

larg  = max(cols0, 18)  # garante atÃ© R (col 18 -> idx 17)
novas = []
N = max(len(E), len(F), len(C), len(L_), len(D))
for i in range(N):
    key = E[i] if i < len(E) else ""
    if not key or key in exist:
        continue

    uni_raw = D[i] if i < len(D) else ""
    uni_map = MAP_UNIDADE.get(norm_acento_up(uni_raw), uni_raw.strip())

    linha = [''] * larg
    linha[0]  = key                             # A â† E
    if larg >= 2:  linha[1]  = F[i] if i<len(F)  else ""  # B â† F
    if larg >= 8:  linha[7]  = C[i] if i<len(C)  else ""  # H â† C
    if larg >= 11: linha[10] = L_[i] if i<len(L_) else "" # K â† L
    if larg >= 18: linha[17] = uni_map                        # R â† D
    novas.append(linha)

if novas:
    start = rows0 + 2
    with_retry(w_dst.append_rows, novas, value_input_option='USER_ENTERED', desc="append CICLO")
    highlight(w_dst, start, len(novas), end_col="Q")
    rows0 += len(novas)
    log(f"âœ… {len(novas)} linhas da CICLO inseridas.")
else:
    log("â„¹ï¸  Nenhum novo ID da CICLO a inserir.")

# ---------- LV CICLO (Bâ†’A, Câ†’B, 'SOMENTE LV'â†’H, Unidadeâ†’R) ----------
log("ğŸ”— LV CICLO (Bâ†’A, Câ†’B, 'SOMENTE LV'â†’H, Unidadeâ†’R)")
w_lv = with_retry(b_dst.worksheet, "LV CICLO", desc="ws LV")

A_uni = load_col(w_lv, "A")   # Unidade (bruta)
B_id  = load_col(w_lv, "B")   # â†’ A
C_prj = load_col(w_lv, "C")   # â†’ B

# Reaproveita o conjunto existente lido antes
exist = set(exist)  # jÃ¡ contÃ©m A2:A do destino

novas_lv=[]; cont={}
N = max(len(A_uni), len(B_id), len(C_prj))
for i in range(N):
    vid = B_id[i] if i < len(B_id) else ""
    if not vid or vid in exist:
        continue

    uni_raw = A_uni[i] if i < len(A_uni) else ""
    uni_map = MAP_UNIDADE.get(norm_acento_up(uni_raw), uni_raw.strip())

    linha = [''] * larg
    linha[0]  = vid                            # A â† B
    if larg >= 2:  linha[1]  = C_prj[i] if i<len(C_prj) else ""  # B â† C
    if larg >= 8:  linha[7]  = "SOMENTE LV"                       # H
    if larg >= 18: linha[17] = uni_map                            # R â† Unidade
    novas_lv.append(linha)
    cont[uni_map] = cont.get(uni_map, 0) + 1

if novas_lv:
    start = rows0 + 2
    with_retry(w_dst.append_rows, novas_lv, value_input_option='USER_ENTERED', desc="append LV")
    highlight(w_dst, start, len(novas_lv), end_col="Q")
    rows0 += len(novas_lv)
    resumo = ", ".join(f"{u}: {q}" for u,q in sorted(cont.items()))
    if resumo: log(f"ğŸ“Œ Unidades atribuÃ­das (R): {resumo}")
    log(f"âœ… {len(novas_lv)} linhas da LV CICLO inseridas.")
else:
    log("â„¹ï¸  Nenhum novo ID da LV CICLO a inserir.")

# ---------- TIMESTAMP ----------
with_retry(w_dst.update, range_name="T2",
           values=[[f"Atualizado em: {now()}"]], value_input_option='USER_ENTERED')
log(f"ğŸ‰ Fim â€” {rows0} linhas totais inseridas/atualizadas.")
